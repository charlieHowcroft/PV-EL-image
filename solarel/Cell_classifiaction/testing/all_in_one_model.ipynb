{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "import tensorflow  as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           image_name  good  crack  corrossion\n",
      "0         image_0.jpg  0.33   0.00        0.66\n",
      "1         image_1.jpg  0.33   0.00        0.66\n",
      "2         image_3.jpg  0.33   0.00        0.66\n",
      "3         image_4.jpg  0.33   0.00        0.66\n",
      "4         image_5.jpg  0.66   0.00        0.33\n",
      "...               ...   ...    ...         ...\n",
      "5289  2_image_993.jpg  0.33   0.66        0.00\n",
      "5290  0_image_994.jpg  0.66   0.33        0.00\n",
      "5291  1_image_994.jpg  0.66   0.33        0.00\n",
      "5292  2_image_994.jpg  0.66   0.33        0.00\n",
      "5293  2_image_998.jpg  1.00   0.00        0.00\n",
      "\n",
      "[5294 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"slim_dataset.csv\"\n",
    "labels_df = pd.read_csv(csv_path)\n",
    "print(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/chuck/OneDrive/Desktop/Honors/models/Cell_classification/All_in_one/fine_tuned_model/\"\n",
    "loaded_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"C:/Users/chuck/OneDrive/Desktop/Honors/propper_datasets/images\"\n",
    "column_names = labels_df.columns.tolist()\n",
    "prediction_df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_numbers(image, prediction, truth):\n",
    "    # Define the font and font scale\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "\n",
    "    # Define the position and color for each number label\n",
    "    positions = [(10, 20), (10, 50), (10, 90)]\n",
    "    colors = [(0, 255, 0), (0, 0, 255), (255, 255, 0)]\n",
    "\n",
    "    # Loop over each number and label, and write it onto the image\n",
    "    for i, number in enumerate(prediction):\n",
    "        label = f\"{['good', 'crack', 'corrosion'][i]}: {number:.2f} ({truth[i]:.2f})\"\n",
    "        cv2.putText(image, label, positions[i], font, font_scale, (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, label, positions[i], font, font_scale, colors[i], 1, cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "...loading 0.0%...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "...loading 0.02%...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "...loading 0.04%...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "...loading 0.06%...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "...loading 0.08%...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chuck\\OneDrive\\Desktop\\Honors\\solarEL\\solarel\\Cell_classifiaction\\testing\\all_in_one_model.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chuck/OneDrive/Desktop/Honors/solarEL/solarel/Cell_classifiaction/testing/all_in_one_model.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))  \u001b[39m# resize to model input size\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chuck/OneDrive/Desktop/Honors/solarEL/solarel/Cell_classifiaction/testing/all_in_one_model.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img)\u001b[39m/\u001b[39m\u001b[39m128\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m     \u001b[39m# convert to numpy array\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chuck/OneDrive/Desktop/Honors/solarEL/solarel/Cell_classifiaction/testing/all_in_one_model.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pred \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mexpand_dims(img_array, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chuck/OneDrive/Desktop/Honors/solarEL/solarel/Cell_classifiaction/testing/all_in_one_model.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m row \u001b[39m=\u001b[39m [image_name] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chuck/OneDrive/Desktop/Honors/solarEL/solarel/Cell_classifiaction/testing/all_in_one_model.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m prediction_df\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(prediction_df)] \u001b[39m=\u001b[39m row\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   2254\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in labels_df.iterrows():\n",
    "    image_name = row[\"image_name\"]\n",
    "    image_path = image_folder + \"/\" + image_name\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))  # resize to model input size\n",
    "    img_array = np.array(img)/128 - 1     # convert to numpy array\n",
    "\n",
    "    pred = loaded_model.predict(np.expand_dims(img_array, axis=0))[0]\n",
    "    row = [image_name] + list(pred)\n",
    "    prediction_df.loc[len(prediction_df)] = row\n",
    "    print(f\"...loading {round(100*index/len(labels_df), 2)}%...\")\n",
    "\n",
    "# prediction_df.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: [], 0.33: [], 0.66: [], 1.0: []}\n",
      "{0.0: (4057, 24, 1, 0), 0.33: (102, 300, 91, 3), 0.66: (18, 84, 236, 46), 1.0: (8, 1, 8, 315)}\n"
     ]
    }
   ],
   "source": [
    "prediction_df = pd.read_csv(\"predictions_all_in_one.csv\")\n",
    "key = 'corrossion'\n",
    "\n",
    "def count_numbers_in_ranges(numbers):\n",
    "    range_counts = [0, 0, 0, 0]\n",
    "\n",
    "    for num in numbers:\n",
    "        if 0 <= num <= 0.165:\n",
    "            range_counts[0] += 1\n",
    "        elif 0.165 < num <= 0.5:\n",
    "            range_counts[1] += 1\n",
    "        elif 0.5 < num <= 0.825:\n",
    "            range_counts[2] += 1\n",
    "        elif 0.825 < num <= 1:\n",
    "            range_counts[3] += 1\n",
    "\n",
    "    return tuple(range_counts)\n",
    "\n",
    "\n",
    "def all_in_one_confusion_matrix(labels_df, prediction_df):\n",
    "    grouped = labels_df.groupby(key)['image_name'].agg(list)\n",
    "    good_labels_dict = grouped.to_dict()\n",
    "    good_pred_dict = {key: [] for key in good_labels_dict}\n",
    "    print(good_pred_dict)\n",
    "\n",
    "    for score in good_labels_dict:\n",
    "        predictions = []\n",
    "\n",
    "        for image_name in good_labels_dict[score]:\n",
    "            row = prediction_df.loc[prediction_df['image_name'] == image_name]\n",
    "\n",
    "            predictions.append(row[key].values[0])\n",
    "            \n",
    "        good_pred_dict[score] = count_numbers_in_ranges(predictions)\n",
    "    \n",
    "    return good_pred_dict\n",
    "\n",
    "\n",
    "\n",
    "x = all_in_one_confusion_matrix(labels_df, prediction_df)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib qt\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for true_class, counts in x.items():\n",
    "    for pred_class, count in enumerate(counts):\n",
    "        true_labels.extend([true_class] * count)\n",
    "        predicted_labels.extend([pred_class] * count)\n",
    "\n",
    "# Create a confusion matrix\n",
    "truth = np.round(np.array(true_labels)/0.33)\n",
    "conf_matrix = confusion_matrix(truth, predicted_labels)\n",
    "\n",
    "# Calculate percentages along the rows\n",
    "row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "conf_matrix_percentages = conf_matrix / row_sums * 100\n",
    "\n",
    "# Plot the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "heatmap = sns.heatmap(conf_matrix_percentages, annot=True, fmt=\".1f\", cmap=\"Blues\",\n",
    "            xticklabels=[\"0-0.165\", \"0.165-0.5\", \"0.5-0.825\", \"0.825-1\"],\n",
    "            yticklabels=[\"0.0\", \"0.33\", \"0.66\", \"1.0\"])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Corrosion Class Confusion Matrix')\n",
    "\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Percentage of Predictions (%)', rotation=90, labelpad=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
